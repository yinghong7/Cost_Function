{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers, layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Productivity improvement (CB1,CB2,CB4,CB5,CB7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_train_scale.csv', \n",
    "                    delimiter = ',', usecols = (2,3,4,5,6), skip_header=2)\n",
    "y_1o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_train_scale.csv', \n",
    "                   delimiter =',', usecols = (29), skip_header=2).reshape (54,1)\n",
    "x_2 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_scale.csv', \n",
    "                    delimiter = ',', usecols = (2,3,4,5,6), skip_header=1)\n",
    "y_2o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_scale.csv',\n",
    "                      delimiter =',', usecols = (29),skip_header=1).reshape (14,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder ()\n",
    "enc.fit (y_1o)\n",
    "y_1 = enc.transform(y_1o).toarray()\n",
    "y_2 = enc.transform(y_2o).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_whole = np.vstack ((y_1, y_2)).astype(np.float32)\n",
    "x_whole = np.vstack ((x_1, x_2)).astype(np.float32)\n",
    "x_traind = x_1\n",
    "x_test = x_2\n",
    "y_traind = y_1\n",
    "y_test = y_2\n",
    "x_train, x_cv, y_train, y_cv = train_test_split (x_1,y_1,test_size=0.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46 samples, validate on 8 samples\n",
      "Epoch 1/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6688 - binary_accuracy: 0.6576 - val_loss: 0.5029 - val_binary_accuracy: 0.7500\n",
      "Epoch 2/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6618 - binary_accuracy: 0.6576 - val_loss: 0.5012 - val_binary_accuracy: 0.7500\n",
      "Epoch 3/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6595 - binary_accuracy: 0.6576 - val_loss: 0.4984 - val_binary_accuracy: 0.7500\n",
      "Epoch 4/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6554 - binary_accuracy: 0.6576 - val_loss: 0.4960 - val_binary_accuracy: 0.7500\n",
      "Epoch 5/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6529 - binary_accuracy: 0.6576 - val_loss: 0.4935 - val_binary_accuracy: 0.7500\n",
      "Epoch 6/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6493 - binary_accuracy: 0.6630 - val_loss: 0.4905 - val_binary_accuracy: 0.7500\n",
      "Epoch 7/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6457 - binary_accuracy: 0.6739 - val_loss: 0.4880 - val_binary_accuracy: 0.7500\n",
      "Epoch 8/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.6739 - val_loss: 0.4854 - val_binary_accuracy: 0.7812\n",
      "Epoch 9/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6388 - binary_accuracy: 0.6739 - val_loss: 0.4828 - val_binary_accuracy: 0.8125\n",
      "Epoch 10/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6360 - binary_accuracy: 0.6739 - val_loss: 0.4796 - val_binary_accuracy: 0.7812\n",
      "Epoch 11/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6322 - binary_accuracy: 0.6902 - val_loss: 0.4782 - val_binary_accuracy: 0.7812\n",
      "Epoch 12/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6299 - binary_accuracy: 0.6902 - val_loss: 0.4748 - val_binary_accuracy: 0.7812\n",
      "Epoch 13/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.6902 - val_loss: 0.4732 - val_binary_accuracy: 0.7812\n",
      "Epoch 14/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6229 - binary_accuracy: 0.6902 - val_loss: 0.4694 - val_binary_accuracy: 0.7812\n",
      "Epoch 15/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6204 - binary_accuracy: 0.6957 - val_loss: 0.4664 - val_binary_accuracy: 0.7500\n",
      "Epoch 16/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6173 - binary_accuracy: 0.6957 - val_loss: 0.4630 - val_binary_accuracy: 0.7500\n",
      "Epoch 17/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6132 - binary_accuracy: 0.7011 - val_loss: 0.4581 - val_binary_accuracy: 0.7500\n",
      "Epoch 18/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6091 - binary_accuracy: 0.7120 - val_loss: 0.4588 - val_binary_accuracy: 0.7500\n",
      "Epoch 19/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6082 - binary_accuracy: 0.7120 - val_loss: 0.4549 - val_binary_accuracy: 0.7500\n",
      "Epoch 20/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6042 - binary_accuracy: 0.7228 - val_loss: 0.4521 - val_binary_accuracy: 0.7500\n",
      "Epoch 21/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6008 - binary_accuracy: 0.7283 - val_loss: 0.4515 - val_binary_accuracy: 0.7500\n",
      "Epoch 22/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.7283 - val_loss: 0.4512 - val_binary_accuracy: 0.7500\n",
      "Epoch 23/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.7283 - val_loss: 0.4499 - val_binary_accuracy: 0.7500\n",
      "Epoch 24/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5945 - binary_accuracy: 0.7283 - val_loss: 0.4487 - val_binary_accuracy: 0.7500\n",
      "Epoch 25/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5924 - binary_accuracy: 0.7283 - val_loss: 0.4490 - val_binary_accuracy: 0.7500\n",
      "Epoch 26/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5904 - binary_accuracy: 0.7283 - val_loss: 0.4481 - val_binary_accuracy: 0.7500\n",
      "Epoch 27/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5885 - binary_accuracy: 0.7283 - val_loss: 0.4478 - val_binary_accuracy: 0.7500\n",
      "Epoch 28/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.7283 - val_loss: 0.4471 - val_binary_accuracy: 0.7812\n",
      "Epoch 29/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5847 - binary_accuracy: 0.7283 - val_loss: 0.4470 - val_binary_accuracy: 0.7812\n",
      "Epoch 30/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5838 - binary_accuracy: 0.7283 - val_loss: 0.4460 - val_binary_accuracy: 0.7812\n",
      "Epoch 31/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5818 - binary_accuracy: 0.7283 - val_loss: 0.4445 - val_binary_accuracy: 0.7812\n",
      "Epoch 32/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5800 - binary_accuracy: 0.7283 - val_loss: 0.4441 - val_binary_accuracy: 0.7812\n",
      "Epoch 33/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5790 - binary_accuracy: 0.7283 - val_loss: 0.4437 - val_binary_accuracy: 0.7812\n",
      "Epoch 34/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5776 - binary_accuracy: 0.7337 - val_loss: 0.4429 - val_binary_accuracy: 0.7812\n",
      "Epoch 35/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5759 - binary_accuracy: 0.7337 - val_loss: 0.4421 - val_binary_accuracy: 0.7812\n",
      "Epoch 36/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5745 - binary_accuracy: 0.7337 - val_loss: 0.4420 - val_binary_accuracy: 0.7812\n",
      "Epoch 37/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5732 - binary_accuracy: 0.7391 - val_loss: 0.4417 - val_binary_accuracy: 0.7812\n",
      "Epoch 38/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5717 - binary_accuracy: 0.7391 - val_loss: 0.4419 - val_binary_accuracy: 0.7812\n",
      "Epoch 39/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5701 - binary_accuracy: 0.7391 - val_loss: 0.4427 - val_binary_accuracy: 0.7812\n",
      "Epoch 40/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5683 - binary_accuracy: 0.7391 - val_loss: 0.4423 - val_binary_accuracy: 0.7812\n",
      "14/14 [==============================] - ETA: 0s\n",
      "[0.56513655185699463, 0.75]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4;\n",
    "\n",
    "model = Sequential ()\n",
    "model.add (Dense (units = 11, input_dim = 5))\n",
    "model.add (layers.Activation ('tanh'))\n",
    "model.add (Dense (units = 11))\n",
    "#model.add (layers.Activation ('tanh'))\n",
    "#model.add (Dense (units = 11))\n",
    "#model.add (layers.Activation ('tanh'))\n",
    "#model.add (Dense (units = 16))\n",
    "model.add (Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "#sgd = optimizer.SGD (lr=0.01, momentum = 0, decay =0, nestrov = False)\n",
    "model.compile (loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "\n",
    "History = model.fit(x_train, y_train,\n",
    "                    batch_size=15,\n",
    "                    epochs=40,\n",
    "                    verbose=1, validation_data=(x_cv, y_cv))\n",
    "\n",
    "print(model.evaluate (x_test, y_test, batch_size = 15, verbose =1))\n",
    "\n",
    "#help (model.evaluate)\n",
    "#this is the output units\n",
    "\n",
    "y_pred_train = model.predict (x_train)\n",
    "y_pred_cv = model.predict (x_cv)\n",
    "y_pred_test = model.predict (x_test)\n",
    "y_pred_whole = np.vstack ((y_pred_train, y_pred_cv, y_pred_test)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t(x) for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#save model to json, weights to HDF5\n",
    "model_json = model.to_json ()\n",
    "with open ('model_lod_productiviity_improve_a.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model_lod_productiviity_improve_a.h5')\n",
    "print ('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model\n",
    "json_file = open('model_lod_productiviity_improve_a.json', 'r')\n",
    "loaded_model_json = json_file.read ()\n",
    "json_file.close ()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('model_lod_productiviity_improve_a.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s\n",
      "[0.56513655185699463, 0.75]\n",
      "[[-5.42719297  0.         -4.82325315 -4.47360173]\n",
      " [-4.20982778 -4.951462    0.         -3.21113944]\n",
      " [-0.88172376 -1.52010173 -2.79351346  0.        ]\n",
      " [ 0.         -2.21382469 -1.83994904 -0.3964141 ]\n",
      " [-2.96225809 -2.29478329  0.         -0.38900256]\n",
      " [-0.65744609  0.         -0.98634332 -0.08596033]\n",
      " [-0.67225248 -1.80695876 -2.50010826  0.        ]\n",
      " [-1.19168922 -0.36519259  0.         -0.19582748]\n",
      " [-0.78011364 -0.02923638  0.         -0.12578428]\n",
      " [-0.37026063 -0.46207145 -0.38329333  0.        ]\n",
      " [-2.96496138 -2.7046594  -3.24551404  0.        ]\n",
      " [-3.88583012 -3.42166677  0.         -2.16614574]\n",
      " [-1.24191999 -2.35340625 -0.90603322  0.        ]\n",
      " [-3.31119619 -2.03805998 -0.72856218  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "print(loaded_model.evaluate (x_test, y_test, batch_size = 20, verbose =1))\n",
    "y_pred_test = loaded_model.predict (x_test)\n",
    "\n",
    "                     \n",
    "i = 0;\n",
    "j = 0;\n",
    "m = np.zeros((14,4));\n",
    "for i in range (14):\n",
    "    max = 0.0000001;\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j))>=max:\n",
    "            max = y_pred_test.item ((i,j))\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j)) ==max:\n",
    "            np.put(m, [4*i+j], [1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "selected_LOD = np.zeros((14,1));\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        if m.item((i,j))>0:\n",
    "            selected_LOD_1 = m.item((i,j))*y_pred_test.item((i,j));\n",
    "            np.put(selected_LOD, [i], [selected_LOD_1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "cf = np.zeros((14,4))\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        cf_1 = y_pred_test.item((i,j))-selected_LOD.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf, [4*i+j], [cf_2])\n",
    "print (cf)        \n",
    "np.savetxt('y_cost_LODproduct_improve.csv', cf, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
