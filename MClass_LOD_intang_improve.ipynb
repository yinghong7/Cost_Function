{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers, layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intangible improvement (IM6, CB8,OS3,IM4,IM5,OS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_traintest_py.csv', \n",
    "                    delimiter = ',', usecols = (25,38,18,23,24,19), skip_header=1)\n",
    "y_1o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_traintest_py.csv', \n",
    "                   delimiter =',', usecols = (65), skip_header=1).reshape (54,1)\n",
    "x_2 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_py.csv', \n",
    "                    delimiter = ',', usecols = (25,38,18,23,24,19), skip_header=1)\n",
    "y_2o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_py.csv',\n",
    "                      delimiter =',', usecols = (65),skip_header=1).reshape (14,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder ()\n",
    "enc.fit (y_1o)\n",
    "y_train = enc.transform(y_1o).toarray()\n",
    "y_test = enc.transform(y_2o).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler ()\n",
    "scaler.fit (x_1)\n",
    "x_train = scaler.transform (x_1)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split (x_train,y_train,test_size=0.13)\n",
    "x_test = scaler.transform (x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46 samples, validate on 8 samples\n",
      "Epoch 1/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5996 - binary_accuracy: 0.7337 - val_loss: 0.6186 - val_binary_accuracy: 0.6875\n",
      "Epoch 2/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.7337 - val_loss: 0.6168 - val_binary_accuracy: 0.6875\n",
      "Epoch 3/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5972 - binary_accuracy: 0.7337 - val_loss: 0.6151 - val_binary_accuracy: 0.7188\n",
      "Epoch 4/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5960 - binary_accuracy: 0.7337 - val_loss: 0.6135 - val_binary_accuracy: 0.7188\n",
      "Epoch 5/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5949 - binary_accuracy: 0.7337 - val_loss: 0.6118 - val_binary_accuracy: 0.7188\n",
      "Epoch 6/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5938 - binary_accuracy: 0.7337 - val_loss: 0.6102 - val_binary_accuracy: 0.7188\n",
      "Epoch 7/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5927 - binary_accuracy: 0.7337 - val_loss: 0.6087 - val_binary_accuracy: 0.7188\n",
      "Epoch 8/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.7337 - val_loss: 0.6071 - val_binary_accuracy: 0.7188\n",
      "Epoch 9/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5906 - binary_accuracy: 0.7337 - val_loss: 0.6056 - val_binary_accuracy: 0.7188\n",
      "Epoch 10/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5896 - binary_accuracy: 0.7337 - val_loss: 0.6042 - val_binary_accuracy: 0.7188\n",
      "Epoch 11/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5886 - binary_accuracy: 0.7337 - val_loss: 0.6027 - val_binary_accuracy: 0.7188\n",
      "Epoch 12/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5876 - binary_accuracy: 0.7337 - val_loss: 0.6014 - val_binary_accuracy: 0.7500\n",
      "Epoch 13/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.7391 - val_loss: 0.6000 - val_binary_accuracy: 0.7500\n",
      "Epoch 14/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5857 - binary_accuracy: 0.7391 - val_loss: 0.5987 - val_binary_accuracy: 0.7500\n",
      "Epoch 15/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5847 - binary_accuracy: 0.7446 - val_loss: 0.5974 - val_binary_accuracy: 0.7500\n",
      "Epoch 16/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5838 - binary_accuracy: 0.7446 - val_loss: 0.5961 - val_binary_accuracy: 0.7500\n",
      "Epoch 17/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5829 - binary_accuracy: 0.7446 - val_loss: 0.5948 - val_binary_accuracy: 0.7500\n",
      "Epoch 18/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5821 - binary_accuracy: 0.7446 - val_loss: 0.5936 - val_binary_accuracy: 0.7500\n",
      "Epoch 19/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5812 - binary_accuracy: 0.7446 - val_loss: 0.5924 - val_binary_accuracy: 0.7500\n",
      "Epoch 20/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5804 - binary_accuracy: 0.7446 - val_loss: 0.5913 - val_binary_accuracy: 0.7500\n",
      "Epoch 21/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5795 - binary_accuracy: 0.7446 - val_loss: 0.5901 - val_binary_accuracy: 0.7500\n",
      "Epoch 22/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5787 - binary_accuracy: 0.7446 - val_loss: 0.5890 - val_binary_accuracy: 0.7500\n",
      "Epoch 23/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5779 - binary_accuracy: 0.7500 - val_loss: 0.5879 - val_binary_accuracy: 0.7500\n",
      "Epoch 24/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5771 - binary_accuracy: 0.7500 - val_loss: 0.5868 - val_binary_accuracy: 0.7500\n",
      "Epoch 25/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5764 - binary_accuracy: 0.7500 - val_loss: 0.5858 - val_binary_accuracy: 0.7500\n",
      "Epoch 26/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5756 - binary_accuracy: 0.7500 - val_loss: 0.5848 - val_binary_accuracy: 0.7500\n",
      "Epoch 27/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5749 - binary_accuracy: 0.7500 - val_loss: 0.5838 - val_binary_accuracy: 0.7500\n",
      "Epoch 28/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5741 - binary_accuracy: 0.7500 - val_loss: 0.5828 - val_binary_accuracy: 0.7500\n",
      "Epoch 29/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5734 - binary_accuracy: 0.7500 - val_loss: 0.5818 - val_binary_accuracy: 0.7500\n",
      "Epoch 30/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5727 - binary_accuracy: 0.7500 - val_loss: 0.5809 - val_binary_accuracy: 0.7500\n",
      "Epoch 31/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5720 - binary_accuracy: 0.7500 - val_loss: 0.5800 - val_binary_accuracy: 0.7500\n",
      "Epoch 32/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5713 - binary_accuracy: 0.7500 - val_loss: 0.5791 - val_binary_accuracy: 0.7500\n",
      "Epoch 33/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5707 - binary_accuracy: 0.7554 - val_loss: 0.5782 - val_binary_accuracy: 0.7500\n",
      "Epoch 34/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5700 - binary_accuracy: 0.7554 - val_loss: 0.5774 - val_binary_accuracy: 0.7500\n",
      "Epoch 35/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5694 - binary_accuracy: 0.7554 - val_loss: 0.5765 - val_binary_accuracy: 0.7500\n",
      "Epoch 36/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5687 - binary_accuracy: 0.7554 - val_loss: 0.5757 - val_binary_accuracy: 0.7500\n",
      "Epoch 37/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5681 - binary_accuracy: 0.7554 - val_loss: 0.5749 - val_binary_accuracy: 0.7500\n",
      "Epoch 38/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5675 - binary_accuracy: 0.7554 - val_loss: 0.5741 - val_binary_accuracy: 0.7500\n",
      "Epoch 39/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5669 - binary_accuracy: 0.7554 - val_loss: 0.5733 - val_binary_accuracy: 0.7500\n",
      "Epoch 40/40\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5663 - binary_accuracy: 0.7554 - val_loss: 0.5726 - val_binary_accuracy: 0.7500\n",
      "14/14 [==============================] - ETA: 0s\n",
      "[0.58797603845596313, 0.7321428656578064]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4;\n",
    "\n",
    "model = Sequential ()\n",
    "model.add (Dense (units = 25, input_dim = 6))\n",
    "model.add (layers.Activation ('tanh'))\n",
    "model.add (Dense (units = 25))\n",
    "model.add (layers.Activation ('tanh'))\n",
    "model.add (Dense (units = 25))\n",
    "model.add (layers.Activation ('tanh'))\n",
    "#model.add (Dense (units = 16))\n",
    "model.add (Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "#sgd = optimizer.SGD (lr=0.01, momentum = 0, decay =0, nestrov = False)\n",
    "model.compile (loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "\n",
    "History = model.fit(x_train, y_train,\n",
    "                    batch_size=60,\n",
    "                    epochs=40,\n",
    "                    verbose=1, validation_data=(x_cv, y_cv))\n",
    "\n",
    "print(model.evaluate (x_test, y_test, batch_size = 60, verbose =1))\n",
    "\n",
    "#help (model.evaluate)\n",
    "#this is the output units\n",
    "\n",
    "y_pred_train = model.predict (x_train)\n",
    "y_pred_cv = model.predict (x_cv)\n",
    "y_pred_test = model.predict (x_test)\n",
    "y_pred_whole = np.vstack ((y_pred_train, y_pred_cv, y_pred_test)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t(x) for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#save model to json, weights to HDF5\n",
    "model_json = model.to_json ()\n",
    "with open ('model_lod_intang_improve_a.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model_lod_intang_improve_a.h5')\n",
    "print ('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model\n",
    "json_file = open('model_lod_intang_improve_a.json', 'r')\n",
    "loaded_model_json = json_file.read ()\n",
    "json_file.close ()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('model_lod_intang_improve_a.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s\n",
      "[0.58797603845596313, 0.7321428656578064]\n",
      "[[ 0.25270429  0.30054247  0.24075301  0.20600027]\n",
      " [ 0.23971331  0.36091769  0.21748932  0.18187971]\n",
      " [ 0.61223918  0.09068605  0.1545907   0.14248402]\n",
      " [ 0.17407142  0.18672027  0.34739488  0.2918134 ]\n",
      " [ 0.11045768  0.23836249  0.37627441  0.27490544]\n",
      " [ 0.28150579  0.28275043  0.22472489  0.21101883]\n",
      " [ 0.2624343   0.22082227  0.25887683  0.25786659]\n",
      " [ 0.21612778  0.36057714  0.2239989   0.19929616]\n",
      " [ 0.47204304  0.22568345  0.17846686  0.12380667]\n",
      " [ 0.27568361  0.36351267  0.18194067  0.17886306]\n",
      " [ 0.16537012  0.31121409  0.23299307  0.29042271]\n",
      " [ 0.05760452  0.30553383  0.23661119  0.40025052]\n",
      " [ 0.30253083  0.16091831  0.27868772  0.25786316]\n",
      " [ 0.15130186  0.21743488  0.2392959   0.39196736]]\n",
      "[[-0.47838181  0.         -0.59789464 -0.94542205]\n",
      " [-1.21204376  0.         -1.4342837  -1.79037973]\n",
      " [ 0.         -5.21553129 -4.57648486 -4.69755158]\n",
      " [-1.73323467 -1.60674617  0.         -0.5558148 ]\n",
      " [-2.65816726 -1.37911916  0.         -1.01368964]\n",
      " [-0.01244634  0.         -0.58025539 -0.71731597]\n",
      " [ 0.         -0.41612029 -0.03557473 -0.04567713]\n",
      " [-1.44449353  0.         -1.36578232 -1.61280975]\n",
      " [ 0.         -2.46359587 -2.93576181 -3.48236367]\n",
      " [-0.87829053  0.         -1.8157199  -1.84649602]\n",
      " [-1.45843968  0.         -0.78221023 -0.20791382]\n",
      " [-3.42646006 -0.94716698 -1.63639337  0.        ]\n",
      " [ 0.         -1.41612515 -0.2384311  -0.44667661]\n",
      " [-2.40665495 -1.74532473 -1.52671456  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "print(loaded_model.evaluate (x_test, y_test, batch_size = 20, verbose =1))\n",
    "y_pred_test = loaded_model.predict (x_test)\n",
    "print(y_pred_test)\n",
    "\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "m = np.zeros((14,4));\n",
    "for i in range (14):\n",
    "    max = 0.0000001;\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j))>=max:\n",
    "            max = y_pred_test.item ((i,j))\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j)) ==max:\n",
    "            np.put(m, [4*i+j], [1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "selected_LOD = np.zeros((14,1));\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        if m.item((i,j))>0:\n",
    "            selected_LOD_1 = m.item((i,j))*y_pred_test.item((i,j));\n",
    "            np.put(selected_LOD, [i], [selected_LOD_1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "cf = np.zeros((14,4))\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        cf_1 = y_pred_test.item((i,j))-selected_LOD.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf, [4*i+j], [cf_2])\n",
    "print (cf)\n",
    "np.savetxt('y_cost_LODintang_improve.csv', cf, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
