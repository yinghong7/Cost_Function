{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers, layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and maintenance cost (IM6, CB8, OS3, IM4, IM5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_train_scale.csv', \n",
    "                    delimiter = ',', usecols = (10,11,12,13,14), skip_header=2)\n",
    "y_1o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_train_scale.csv', \n",
    "                   delimiter =',', usecols = (29), skip_header=2).reshape (54,1)\n",
    "x_2 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_scale.csv', \n",
    "                    delimiter = ',', usecols = (10,11,12,13,14), skip_header=1)\n",
    "y_2o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_scale.csv',\n",
    "                      delimiter =',', usecols = (29),skip_header=1).reshape (14,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder ()\n",
    "enc.fit (y_1o)\n",
    "y_1 = enc.transform(y_1o).toarray()\n",
    "y_2 = enc.transform(y_2o).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_whole = np.vstack ((y_1, y_2)).astype(np.float32)\n",
    "x_whole = np.vstack ((x_1, x_2)).astype(np.float32)\n",
    "x_traind = x_1\n",
    "x_test = x_2\n",
    "y_traind = y_1\n",
    "y_test = y_2\n",
    "x_train, x_cv, y_train, y_cv = train_test_split (x_1,y_1,test_size=0.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46 samples, validate on 8 samples\n",
      "Epoch 1/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5786 - binary_accuracy: 0.7500 - val_loss: 0.5458 - val_binary_accuracy: 0.7812\n",
      "Epoch 2/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5782 - binary_accuracy: 0.7500 - val_loss: 0.5456 - val_binary_accuracy: 0.7812\n",
      "Epoch 3/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5778 - binary_accuracy: 0.7500 - val_loss: 0.5454 - val_binary_accuracy: 0.7812\n",
      "Epoch 4/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5775 - binary_accuracy: 0.7500 - val_loss: 0.5452 - val_binary_accuracy: 0.7812\n",
      "Epoch 5/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5771 - binary_accuracy: 0.7500 - val_loss: 0.5451 - val_binary_accuracy: 0.7812\n",
      "Epoch 6/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5767 - binary_accuracy: 0.7500 - val_loss: 0.5449 - val_binary_accuracy: 0.7812\n",
      "Epoch 7/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5764 - binary_accuracy: 0.7500 - val_loss: 0.5447 - val_binary_accuracy: 0.7812\n",
      "Epoch 8/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5760 - binary_accuracy: 0.7500 - val_loss: 0.5446 - val_binary_accuracy: 0.7812\n",
      "Epoch 9/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5757 - binary_accuracy: 0.7500 - val_loss: 0.5444 - val_binary_accuracy: 0.7812\n",
      "Epoch 10/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5753 - binary_accuracy: 0.7500 - val_loss: 0.5442 - val_binary_accuracy: 0.7812\n",
      "Epoch 11/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5749 - binary_accuracy: 0.7500 - val_loss: 0.5441 - val_binary_accuracy: 0.7812\n",
      "Epoch 12/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5746 - binary_accuracy: 0.7500 - val_loss: 0.5439 - val_binary_accuracy: 0.7812\n",
      "Epoch 13/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5742 - binary_accuracy: 0.7500 - val_loss: 0.5437 - val_binary_accuracy: 0.7812\n",
      "Epoch 14/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5739 - binary_accuracy: 0.7500 - val_loss: 0.5436 - val_binary_accuracy: 0.7812\n",
      "Epoch 15/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5735 - binary_accuracy: 0.7500 - val_loss: 0.5434 - val_binary_accuracy: 0.7812\n",
      "Epoch 16/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5732 - binary_accuracy: 0.7500 - val_loss: 0.5433 - val_binary_accuracy: 0.7812\n",
      "Epoch 17/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5728 - binary_accuracy: 0.7500 - val_loss: 0.5431 - val_binary_accuracy: 0.7812\n",
      "Epoch 18/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5725 - binary_accuracy: 0.7500 - val_loss: 0.5430 - val_binary_accuracy: 0.7812\n",
      "Epoch 19/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5722 - binary_accuracy: 0.7500 - val_loss: 0.5428 - val_binary_accuracy: 0.7812\n",
      "Epoch 20/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5718 - binary_accuracy: 0.7500 - val_loss: 0.5427 - val_binary_accuracy: 0.7812\n",
      "Epoch 21/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5715 - binary_accuracy: 0.7500 - val_loss: 0.5425 - val_binary_accuracy: 0.7812\n",
      "Epoch 22/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5711 - binary_accuracy: 0.7500 - val_loss: 0.5424 - val_binary_accuracy: 0.7812\n",
      "Epoch 23/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5708 - binary_accuracy: 0.7500 - val_loss: 0.5422 - val_binary_accuracy: 0.7812\n",
      "Epoch 24/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5705 - binary_accuracy: 0.7500 - val_loss: 0.5421 - val_binary_accuracy: 0.7812\n",
      "Epoch 25/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5701 - binary_accuracy: 0.7554 - val_loss: 0.5420 - val_binary_accuracy: 0.7812\n",
      "Epoch 26/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5698 - binary_accuracy: 0.7554 - val_loss: 0.5418 - val_binary_accuracy: 0.7812\n",
      "Epoch 27/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5695 - binary_accuracy: 0.7554 - val_loss: 0.5417 - val_binary_accuracy: 0.7812\n",
      "Epoch 28/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5691 - binary_accuracy: 0.7554 - val_loss: 0.5416 - val_binary_accuracy: 0.7812\n",
      "Epoch 29/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5688 - binary_accuracy: 0.7554 - val_loss: 0.5414 - val_binary_accuracy: 0.7812\n",
      "Epoch 30/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5685 - binary_accuracy: 0.7554 - val_loss: 0.5413 - val_binary_accuracy: 0.7812\n",
      "Epoch 31/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5682 - binary_accuracy: 0.7554 - val_loss: 0.5412 - val_binary_accuracy: 0.7812\n",
      "Epoch 32/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5678 - binary_accuracy: 0.7554 - val_loss: 0.5411 - val_binary_accuracy: 0.7812\n",
      "Epoch 33/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5675 - binary_accuracy: 0.7554 - val_loss: 0.5409 - val_binary_accuracy: 0.7812\n",
      "Epoch 34/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5672 - binary_accuracy: 0.7554 - val_loss: 0.5408 - val_binary_accuracy: 0.7812\n",
      "Epoch 35/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5669 - binary_accuracy: 0.7554 - val_loss: 0.5407 - val_binary_accuracy: 0.7812\n",
      "Epoch 36/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5665 - binary_accuracy: 0.7554 - val_loss: 0.5406 - val_binary_accuracy: 0.7812\n",
      "Epoch 37/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5662 - binary_accuracy: 0.7554 - val_loss: 0.5405 - val_binary_accuracy: 0.7812\n",
      "Epoch 38/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5659 - binary_accuracy: 0.7554 - val_loss: 0.5404 - val_binary_accuracy: 0.7812\n",
      "Epoch 39/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5656 - binary_accuracy: 0.7554 - val_loss: 0.5402 - val_binary_accuracy: 0.7812\n",
      "Epoch 40/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5653 - binary_accuracy: 0.7554 - val_loss: 0.5401 - val_binary_accuracy: 0.7812\n",
      "Epoch 41/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5650 - binary_accuracy: 0.7554 - val_loss: 0.5400 - val_binary_accuracy: 0.7812\n",
      "Epoch 42/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5647 - binary_accuracy: 0.7554 - val_loss: 0.5399 - val_binary_accuracy: 0.7812\n",
      "Epoch 43/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5643 - binary_accuracy: 0.7554 - val_loss: 0.5398 - val_binary_accuracy: 0.7812\n",
      "Epoch 44/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5640 - binary_accuracy: 0.7554 - val_loss: 0.5397 - val_binary_accuracy: 0.7812\n",
      "Epoch 45/45\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5637 - binary_accuracy: 0.7554 - val_loss: 0.5396 - val_binary_accuracy: 0.7812\n",
      "14/14 [==============================] - ETA: 0s\n",
      "[0.49672415852546692, 0.75]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4;\n",
    "\n",
    "model = Sequential ()\n",
    "model.add (Dense (units = 11, input_dim = 5))\n",
    "model.add (layers.Activation ('tanh'))\n",
    "model.add (Dense (units = 11))\n",
    "#model.add (layers.Activation ('tanh'))\n",
    "#model.add (Dense (units = 11))\n",
    "#model.add (layers.Activation ('tanh'))\n",
    "#model.add (Dense (units = 16))\n",
    "model.add (Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "#sgd = optimizer.SGD (lr=0.01, momentum = 0, decay =0, nestrov = False)\n",
    "model.compile (loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "\n",
    "History = model.fit(x_train, y_train,\n",
    "                    batch_size=60,\n",
    "                    epochs=45,\n",
    "                    verbose=1, validation_data=(x_cv, y_cv))\n",
    "\n",
    "print(model.evaluate (x_test, y_test, batch_size = 60, verbose =1))\n",
    "\n",
    "#help (model.evaluate)\n",
    "#this is the output units\n",
    "\n",
    "y_pred_train = model.predict (x_train)\n",
    "y_pred_cv = model.predict (x_cv)\n",
    "y_pred_test = model.predict (x_test)\n",
    "y_pred_whole = np.vstack ((y_pred_train, y_pred_cv, y_pred_test)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t(x) for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#save model to json, weights to HDF5\n",
    "model_json = model.to_json ()\n",
    "with open ('model_lod_install_cost_a.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model_lod_install_cost_a.h5')\n",
    "print ('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model\n",
    "json_file = open('model_lod_install_cost_a.json', 'r')\n",
    "loaded_model_json = json_file.read ()\n",
    "json_file.close ()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('model_lod_install_cost_a.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s\n",
      "[0.49672415852546692, 0.75]\n",
      "[[ 0.12999903  0.18525609  0.24813689  0.43660805]\n",
      " [ 0.3052786   0.41167802  0.12271223  0.16033116]\n",
      " [ 0.22536397  0.33230707  0.25222477  0.1901042 ]\n",
      " [ 0.26198256  0.2689375   0.29300255  0.17607746]\n",
      " [ 0.25923961  0.10333741  0.37598932  0.26143369]\n",
      " [ 0.1730022   0.13998917  0.27344149  0.41356713]\n",
      " [ 0.19649552  0.14710993  0.35660958  0.29978496]\n",
      " [ 0.1829896   0.12966707  0.30954888  0.37779444]\n",
      " [ 0.24978064  0.24108757  0.21374774  0.29538402]\n",
      " [ 0.2188601   0.18396661  0.22129524  0.37587801]\n",
      " [ 0.27930412  0.38728058  0.16892855  0.16448675]\n",
      " [ 0.2629241   0.1720839   0.31442046  0.25057152]\n",
      " [ 0.28291994  0.21974184  0.30438513  0.19295309]\n",
      " [ 0.31106907  0.39985302  0.16039935  0.12867856]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "print(loaded_model.evaluate (x_test, y_test, batch_size = 20, verbose =1))\n",
    "y_pred_test = loaded_model.predict (x_test)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.0660902  -2.51351953 -1.88471153  0.        ]\n",
      " [-1.06399417  0.         -2.88965784 -2.51346856]\n",
      " [-1.06943101  0.         -0.80082297 -1.42202869]\n",
      " [-0.31019986 -0.24065048  0.         -1.16925091]\n",
      " [-1.16749704 -2.72651911  0.         -1.14555627]\n",
      " [-2.40564927 -2.73577958 -1.40125632  0.        ]\n",
      " [-1.60114065 -2.09499657  0.         -0.56824625]\n",
      " [-1.94804847 -2.48127371 -0.6824556   0.        ]\n",
      " [-0.4560338  -0.54296449 -0.8163628   0.        ]\n",
      " [-1.57017902 -1.91911399 -1.54582769  0.        ]\n",
      " [-1.07976466  0.         -2.18352035 -2.22793832]\n",
      " [-0.51496357 -1.42336562  0.         -0.63848943]\n",
      " [-0.21465182 -0.84643289  0.         -1.11432031]\n",
      " [-0.8878395   0.         -2.39453673 -2.71174461]]\n"
     ]
    }
   ],
   "source": [
    "i = 0;\n",
    "j = 0;\n",
    "m = np.zeros((14,4));\n",
    "for i in range (14):\n",
    "    max = 0.0000001;\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j))>=max:\n",
    "            max = y_pred_test.item ((i,j))\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j)) ==max:\n",
    "            np.put(m, [4*i+j], [1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "selected_LOD = np.zeros((14,1));\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        if m.item((i,j))>0:\n",
    "            selected_LOD_1 = m.item((i,j))*y_pred_test.item((i,j));\n",
    "            np.put(selected_LOD, [i], [selected_LOD_1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "cf = np.zeros((14,4))\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        cf_1 = y_pred_test.item((i,j))-selected_LOD.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf, [4*i+j], [cf_2])\n",
    "print (cf)\n",
    "np.savetxt('y_cost_LODinstall_cost.csv', cf, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
