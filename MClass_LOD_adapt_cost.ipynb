{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Activation \n",
    "from keras import optimizers, layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation cost (CB9,CB10,CB11,CB12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_train_scale.csv', \n",
    "                    delimiter = ',', usecols = (19,20,21,22), skip_header=2)\n",
    "y_1o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_train_scale.csv', \n",
    "                   delimiter =',', usecols = (29), skip_header=2).reshape (54,1)\n",
    "x_2 = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_scale.csv', \n",
    "                    delimiter = ',', usecols = (19,20,21,22), skip_header=1)\n",
    "y_2o = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a1_cv_scale.csv',\n",
    "                      delimiter =',', usecols = (29),skip_header=1).reshape (14,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder ()\n",
    "enc.fit (y_1o)\n",
    "y_1 = enc.transform(y_1o).toarray()\n",
    "y_2 = enc.transform(y_2o).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_whole = np.vstack ((y_1, y_2)).astype(np.float32)\n",
    "x_whole = np.vstack ((x_1, x_2)).astype(np.float32)\n",
    "x_traind = x_1\n",
    "x_test = x_2\n",
    "y_traind = y_1\n",
    "y_test = y_2\n",
    "x_train, x_cv, y_train, y_cv = train_test_split (x_1,y_1,test_size=0.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6358 - binary_accuracy: 0.7500 - val_loss: 0.5288 - val_binary_accuracy: 0.7500\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6338 - binary_accuracy: 0.7500 - val_loss: 0.5294 - val_binary_accuracy: 0.7500\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6318 - binary_accuracy: 0.7500 - val_loss: 0.5300 - val_binary_accuracy: 0.7500\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6298 - binary_accuracy: 0.7500 - val_loss: 0.5306 - val_binary_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6279 - binary_accuracy: 0.7500 - val_loss: 0.5313 - val_binary_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6260 - binary_accuracy: 0.7500 - val_loss: 0.5319 - val_binary_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6242 - binary_accuracy: 0.7500 - val_loss: 0.5325 - val_binary_accuracy: 0.7500\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6223 - binary_accuracy: 0.7500 - val_loss: 0.5331 - val_binary_accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6205 - binary_accuracy: 0.7500 - val_loss: 0.5338 - val_binary_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6187 - binary_accuracy: 0.7500 - val_loss: 0.5344 - val_binary_accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6170 - binary_accuracy: 0.7500 - val_loss: 0.5351 - val_binary_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6152 - binary_accuracy: 0.7500 - val_loss: 0.5358 - val_binary_accuracy: 0.7500\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6135 - binary_accuracy: 0.7500 - val_loss: 0.5364 - val_binary_accuracy: 0.7500\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6118 - binary_accuracy: 0.7500 - val_loss: 0.5371 - val_binary_accuracy: 0.7500\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6102 - binary_accuracy: 0.7500 - val_loss: 0.5378 - val_binary_accuracy: 0.7500\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6085 - binary_accuracy: 0.7500 - val_loss: 0.5385 - val_binary_accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6069 - binary_accuracy: 0.7500 - val_loss: 0.5392 - val_binary_accuracy: 0.7500\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6053 - binary_accuracy: 0.7500 - val_loss: 0.5399 - val_binary_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6038 - binary_accuracy: 0.7500 - val_loss: 0.5406 - val_binary_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6022 - binary_accuracy: 0.7500 - val_loss: 0.5413 - val_binary_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6007 - binary_accuracy: 0.7500 - val_loss: 0.5420 - val_binary_accuracy: 0.7500\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5992 - binary_accuracy: 0.7500 - val_loss: 0.5427 - val_binary_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5977 - binary_accuracy: 0.7500 - val_loss: 0.5434 - val_binary_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5963 - binary_accuracy: 0.7500 - val_loss: 0.5441 - val_binary_accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.7500 - val_loss: 0.5448 - val_binary_accuracy: 0.7500\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5934 - binary_accuracy: 0.7500 - val_loss: 0.5456 - val_binary_accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5920 - binary_accuracy: 0.7500 - val_loss: 0.5463 - val_binary_accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5906 - binary_accuracy: 0.7500 - val_loss: 0.5470 - val_binary_accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5893 - binary_accuracy: 0.7500 - val_loss: 0.5478 - val_binary_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5879 - binary_accuracy: 0.7500 - val_loss: 0.5485 - val_binary_accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5866 - binary_accuracy: 0.7500 - val_loss: 0.5492 - val_binary_accuracy: 0.7500\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5853 - binary_accuracy: 0.7500 - val_loss: 0.5500 - val_binary_accuracy: 0.7500\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5840 - binary_accuracy: 0.7500 - val_loss: 0.5507 - val_binary_accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5827 - binary_accuracy: 0.7500 - val_loss: 0.5515 - val_binary_accuracy: 0.7500\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5815 - binary_accuracy: 0.7500 - val_loss: 0.5522 - val_binary_accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5802 - binary_accuracy: 0.7500 - val_loss: 0.5530 - val_binary_accuracy: 0.7500\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5790 - binary_accuracy: 0.7500 - val_loss: 0.5537 - val_binary_accuracy: 0.7500\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5778 - binary_accuracy: 0.7500 - val_loss: 0.5545 - val_binary_accuracy: 0.7500\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5766 - binary_accuracy: 0.7500 - val_loss: 0.5552 - val_binary_accuracy: 0.7500\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5754 - binary_accuracy: 0.7500 - val_loss: 0.5560 - val_binary_accuracy: 0.7500\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5743 - binary_accuracy: 0.7500 - val_loss: 0.5567 - val_binary_accuracy: 0.7500\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5731 - binary_accuracy: 0.7500 - val_loss: 0.5575 - val_binary_accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5720 - binary_accuracy: 0.7500 - val_loss: 0.5583 - val_binary_accuracy: 0.7500\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5709 - binary_accuracy: 0.7500 - val_loss: 0.5590 - val_binary_accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5698 - binary_accuracy: 0.7500 - val_loss: 0.5598 - val_binary_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5687 - binary_accuracy: 0.7500 - val_loss: 0.5605 - val_binary_accuracy: 0.7500\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5676 - binary_accuracy: 0.7500 - val_loss: 0.5613 - val_binary_accuracy: 0.7500\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5665 - binary_accuracy: 0.7500 - val_loss: 0.5621 - val_binary_accuracy: 0.7500\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5655 - binary_accuracy: 0.7500 - val_loss: 0.5628 - val_binary_accuracy: 0.7500\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5644 - binary_accuracy: 0.7500 - val_loss: 0.5636 - val_binary_accuracy: 0.7500\n",
      "14/14 [==============================] - ETA: 0s\n",
      "[0.57749545574188232, 0.75]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "\n",
    "model = Sequential ()\n",
    "model.add (Dense (units = 29, input_dim = 4))\n",
    "model.add (layers.Activation ('tanh'))\n",
    "model.add (Dense (units = 29))\n",
    "model.add (layers.Activation ('tanh'))\n",
    "model.add (Dense (units = 29))\n",
    "#model.add (layers.Activation ('tanh'))\n",
    "#model.add (Dense (units = 16))\n",
    "model.add (Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "#sgd = optimizer.SGD (lr=0.01, momentum = 0, decay =0, nestrov = False)\n",
    "model.compile (loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "\n",
    "History = model.fit(x_train, y_train,\n",
    "                    batch_size=50,\n",
    "                    epochs=50,\n",
    "                    verbose=1, validation_data=(x_cv, y_cv))\n",
    "\n",
    "print(model.evaluate (x_test, y_test, batch_size = 50, verbose =1))\n",
    "\n",
    "#help (model.evaluate)\n",
    "#this is the output units\n",
    "\n",
    "y_pred_train = model.predict (x_train)\n",
    "y_pred_cv = model.predict (x_cv)\n",
    "y_pred_test = model.predict (x_test)\n",
    "y_pred_whole = np.vstack ((y_pred_train, y_pred_cv, y_pred_test)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t(x) for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#save model to json, weights to HDF5\n",
    "model_json = model.to_json ()\n",
    "with open ('model_lod_adapt_cost_a.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model_lod_adapt_cost_a.h5')\n",
    "print ('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model\n",
    "json_file = open('model_lod_adapt_cost_a.json', 'r')\n",
    "loaded_model_json = json_file.read ()\n",
    "json_file.close ()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('model_lod_adapt_cost_a.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s\n",
      "[0.57749545574188232, 0.75]\n",
      "[[-0.57835236 -1.28792852  0.         -0.28383076]\n",
      " [-0.97886071 -1.18554294  0.         -0.15913606]\n",
      " [-0.06279856  0.         -1.14132196 -0.53873107]\n",
      " [-0.20969063 -0.07426232 -0.23439199  0.        ]\n",
      " [-1.17324546 -0.49163103 -0.40204823  0.        ]\n",
      " [-0.12936503  0.         -1.37849376 -0.7535553 ]\n",
      " [-0.31342298  0.         -0.4436633  -0.05060077]\n",
      " [-0.76307788 -0.72112143 -0.14950991  0.        ]\n",
      " [-1.07603207 -1.23314038 -0.25041759  0.        ]\n",
      " [-0.59000239 -1.01625159  0.         -0.23620605]\n",
      " [-0.86731613 -0.9713757  -0.31519681  0.        ]\n",
      " [-0.43058127 -0.30294806 -0.3461647   0.        ]\n",
      " [-1.35407656 -1.68226808  0.         -0.36144286]\n",
      " [-0.80324158 -0.78267679 -0.82639515  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', \n",
    "               metrics=['binary_accuracy'])\n",
    "print(loaded_model.evaluate (x_test, y_test, batch_size = 20, verbose =1))\n",
    "y_pred_test = loaded_model.predict (x_test)\n",
    "\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "m = np.zeros((14,4));\n",
    "for i in range (14):\n",
    "    max = 0.0000001;\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j))>=max:\n",
    "            max = y_pred_test.item ((i,j))\n",
    "    for j in range (4):\n",
    "        if y_pred_test.item ((i,j)) ==max:\n",
    "            np.put(m, [4*i+j], [1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "selected_LOD = np.zeros((14,1));\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        if m.item((i,j))>0:\n",
    "            selected_LOD_1 = m.item((i,j))*y_pred_test.item((i,j));\n",
    "            np.put(selected_LOD, [i], [selected_LOD_1])\n",
    "\n",
    "i = 0;\n",
    "j = 0;\n",
    "cf = np.zeros((14,4))\n",
    "for i in range (14):\n",
    "    for j in range (4):\n",
    "        cf_1 = y_pred_test.item((i,j))-selected_LOD.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf, [4*i+j], [cf_2])\n",
    "print (cf)\n",
    "np.savetxt('y_cost_LODadapt_cost.csv', cf, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
