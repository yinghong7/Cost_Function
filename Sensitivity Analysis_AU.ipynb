{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers, layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, coverage_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_likert = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a_traintest.csv', \n",
    "                    delimiter = ',', usecols = (20,19,15,21), skip_header=1)\n",
    "y_train_likert = np.genfromtxt ('C:/Users/z5023853/OneDrive - UNSW/Separated dataset_ML/a_train_scale.csv', \n",
    "                   delimiter =',', usecols = (23,24,25,26,27,28,29), skip_header=1)\n",
    "x_test = np.array ([4,4,2,4]).reshape(1,4)\n",
    "y_test = np.array ([1,1,0,0,1,0,0,0]).reshape(1,8)\n",
    "x_test1N = x_test*0.9\n",
    "x_test1P = x_test*1.1\n",
    "x_test3N = x_test*0.7\n",
    "x_test3P = x_test*1.3\n",
    "x_test5N = x_test*0.5\n",
    "x_test5P = x_test*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\z5023853\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler ()\n",
    "scaler.fit (x_train_likert)\n",
    "x_test0 = scaler.transform (x_test)\n",
    "x_test1N = scaler.transform (x_test1N)\n",
    "x_test1P = scaler.transform (x_test1P)\n",
    "x_test3N = scaler.transform (x_test3N)\n",
    "x_test3P = scaler.transform (x_test3P)\n",
    "x_test5N = scaler.transform (x_test5N)\n",
    "x_test5P = scaler.transform (x_test5P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model_app_train_cost_a.json', 'r')\n",
    "loaded_model_json = json_file.read ()\n",
    "json_file.close ()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('model_app_train_cost_a.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y Predicted [[ 0.53215224  0.22891422  0.08407179  0.27004534  0.2008744  -0.05733635\n",
      "   0.29939848]]\n",
      "-10% y Predicted [[ 0.55145711  0.19383997  0.06439297  0.27887583  0.09819625  0.01872637\n",
      "   0.2542879 ]]\n",
      "+10% y Predicted [[ 0.50451249  0.25755033  0.08745068  0.26224577  0.29646671 -0.128536\n",
      "   0.33833277]]\n",
      "-30% y Predicted [[ 0.55754387  0.09521054  0.01732635  0.27014682 -0.07847723  0.1886801\n",
      "   0.21917285]]\n",
      "+30% y Predicted [[ 0.44327274  0.30586109  0.02594188  0.27902824  0.42991808 -0.26890841\n",
      "   0.33618918]]\n",
      "-50% y Predicted [[ 0.53536516 -0.03421399 -0.00675627  0.22083743 -0.18765116  0.35840893\n",
      "   0.27584177]]\n",
      "+50% y Predicted [[ 0.39014548  0.35065058 -0.09528692  0.33713764  0.48908487 -0.40541956\n",
      "   0.22827892]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics=['binary_accuracy'])\n",
    "print ('Original y Predicted',loaded_model.predict (x_test0))\n",
    "print ('-10% y Predicted',loaded_model.predict (x_test1N))\n",
    "print ('+10% y Predicted',loaded_model.predict (x_test1P))\n",
    "print ('-30% y Predicted',loaded_model.predict (x_test3N))\n",
    "print ('+30% y Predicted',loaded_model.predict (x_test3P))\n",
    "print ('-50% y Predicted',loaded_model.predict (x_test5N))\n",
    "print ('+50% y Predicted',loaded_model.predict (x_test5P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = loaded_model.predict (x_test0).reshape (1,7)\n",
    "y_pred1N = loaded_model.predict (x_test1N).reshape (1,7)\n",
    "y_pred1P = loaded_model.predict (x_test1P).reshape (1,7)\n",
    "y_pred3N = loaded_model.predict (x_test3N).reshape (1,7)\n",
    "y_pred3P = loaded_model.predict (x_test3P).reshape (1,7)\n",
    "y_pred5N = loaded_model.predict (x_test5N).reshape (1,7)\n",
    "y_pred5P = loaded_model.predict (x_test5P).reshape (1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x10 = y_pred0 [:,0].reshape(1,1);\n",
    "x20 = y_pred0 [:,1].reshape(1,1);\n",
    "x30 = y_pred0 [:,2].reshape(1,1);\n",
    "x40 = y_pred0 [:,3].reshape(1,1);\n",
    "x50 = y_pred0 [:,4].reshape(1,1);\n",
    "x60 = y_pred0 [:,5].reshape(1,1);\n",
    "x70 = y_pred0 [:,6].reshape(1,1);\n",
    "\n",
    "\n",
    "\n",
    "x11N = y_pred1N [:,0].reshape(1,1);\n",
    "x21N = y_pred1N [:,1].reshape(1,1);\n",
    "x31N = y_pred1N [:,2].reshape(1,1);\n",
    "x41N = y_pred1N [:,3].reshape(1,1);\n",
    "x51N = y_pred1N [:,4].reshape(1,1);\n",
    "x61N = y_pred1N [:,5].reshape(1,1);\n",
    "x71N = y_pred1N [:,6].reshape(1,1);\n",
    "\n",
    "\n",
    "x11P = y_pred1P [:,0].reshape(1,1);\n",
    "x21P = y_pred1P [:,1].reshape(1,1);\n",
    "x31P = y_pred1P [:,2].reshape(1,1);\n",
    "x41P = y_pred1P [:,3].reshape(1,1);\n",
    "x51P = y_pred1P [:,4].reshape(1,1);\n",
    "x61P = y_pred1P [:,5].reshape(1,1);\n",
    "x71P = y_pred1P [:,6].reshape(1,1);\n",
    "\n",
    "\n",
    "x13P = y_pred3P [:,0].reshape(1,1);\n",
    "x23P = y_pred3P [:,1].reshape(1,1);\n",
    "x33P = y_pred3P [:,2].reshape(1,1);\n",
    "x43P = y_pred3P [:,3].reshape(1,1);\n",
    "x53P = y_pred3P [:,4].reshape(1,1);\n",
    "x63P = y_pred3P [:,5].reshape(1,1);\n",
    "x73P = y_pred3P [:,6].reshape(1,1);\n",
    "\n",
    "\n",
    "x13N = y_pred3N [:,0].reshape(1,1);\n",
    "x23N = y_pred3N [:,1].reshape(1,1);\n",
    "x33N = y_pred3N [:,2].reshape(1,1);\n",
    "x43N = y_pred3N [:,3].reshape(1,1);\n",
    "x53N = y_pred3N [:,4].reshape(1,1);\n",
    "x63N = y_pred3N [:,5].reshape(1,1);\n",
    "x73N = y_pred3N [:,6].reshape(1,1);\n",
    "\n",
    "\n",
    "x15P = y_pred5P [:,0].reshape(1,1);\n",
    "x25P = y_pred5P [:,1].reshape(1,1);\n",
    "x35P = y_pred5P [:,2].reshape(1,1);\n",
    "x45P = y_pred5P [:,3].reshape(1,1);\n",
    "x55P = y_pred5P [:,4].reshape(1,1);\n",
    "x65P = y_pred5P [:,5].reshape(1,1);\n",
    "x75P = y_pred5P [:,6].reshape(1,1);\n",
    "\n",
    "\n",
    "x15N = y_pred5N [:,0].reshape(1,1);\n",
    "x25N = y_pred5N [:,1].reshape(1,1);\n",
    "x35N = y_pred5N [:,2].reshape(1,1);\n",
    "x45N = y_pred5N [:,3].reshape(1,1);\n",
    "x55N = y_pred5N [:,4].reshape(1,1);\n",
    "x65N = y_pred5N [:,5].reshape(1,1);\n",
    "x75N = y_pred5N [:,6].reshape(1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0;\n",
    "label_cf0 = np.zeros((1,1));\n",
    "for i in range (1):\n",
    "    y_tx0 = -0.78*x10-0.18*x20-0.33*x30-0.27*x40-0.57*x50-0.12*x60-0.25*x70+0.88;\n",
    "    np.put(label_cf0, [i], [y_tx0]);\n",
    "    \n",
    "    \n",
    "label_cf1N = np.zeros((1,1));\n",
    "for i in range (1):\n",
    "    y_tx1N = -0.78*x11N-0.18*x21N-0.33*x31N-0.27*x41N-0.57*x51N-0.12*x61N-0.25*x71N+0.88;\n",
    "    np.put(label_cf1N, [i], [y_tx1N]);\n",
    "label_cf1P= np.zeros((1,1));\n",
    "for i in range (1):\n",
    "    y_tx1P = -0.78*x11P-0.18*x21P-0.33*x31P-0.27*x41P-0.57*x51P-0.12*x61P-0.25*x71P+0.88;\n",
    "    np.put(label_cf1P, [i], [y_tx1P]);\n",
    "    \n",
    "    \n",
    "label_cf3N= np.zeros((1,1));\n",
    "for i in range (1):\n",
    "    y_tx3N = -0.78*x13N-0.18*x23N-0.33*x33N-0.27*x43N-0.57*x53N-0.12*x63N-0.25*x73N+0.88;\n",
    "    np.put(label_cf3N, [i], [y_tx3N]);\n",
    "label_cf3P= np.zeros((1,1));\n",
    "for i in range (1):\n",
    "    y_tx3P = -0.78*x13P-0.18*x23P-0.33*x33P-0.27*x43P-0.57*x53P-0.12*x63P-0.25*x73P+0.88;\n",
    "    np.put(label_cf3P, [i], [y_tx3P]);\n",
    "    \n",
    "    \n",
    "label_cf5N= np.zeros((1,1));\n",
    "for i in range (1):\n",
    "    y_tx5N = -0.78*x15N-0.18*x25N-0.33*x35N-0.27*x45N-0.57*x55N-0.12*x65N-0.25*x75N+0.88;\n",
    "    np.put(label_cf5N, [i], [y_tx5N]);\n",
    "label_cf5P= np.zeros((1,1));\n",
    "for i in range (1):\n",
    "    y_tx5P = -0.78*x15P-0.18*x25P-0.33*x35P-0.27*x45P-0.57*x55P-0.12*x65P-0.25*x75P+0.88;\n",
    "    np.put(label_cf5P, [i], [y_tx5P]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0;\n",
    "j = 0;\n",
    "cf0 = np.zeros((1,7))\n",
    "for i in range (1):\n",
    "    for j in range (7):\n",
    "        cf_1 = y_pred0.item((i,j))-label_cf0.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf0, [7*i+j], [cf_2]);\n",
    "        \n",
    "cf1N = np.zeros((1,7))\n",
    "for i in range (1):\n",
    "    for j in range (7):\n",
    "        cf_1 = y_pred1N.item((i,j))-label_cf1N.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf1N, [7*i+j], [cf_2]);\n",
    "        \n",
    "cf1P = np.zeros((1,7))\n",
    "for i in range (1):\n",
    "    for j in range (7):\n",
    "        cf_1 = y_pred1P.item((i,j))-label_cf1P.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf1P, [7*i+j], [cf_2]);\n",
    "\n",
    "cf3N = np.zeros((1,7))\n",
    "for i in range (1):\n",
    "    for j in range (7):\n",
    "        cf_1 = y_pred3N.item((i,j))-label_cf3N.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf3N, [7*i+j], [cf_2]);\n",
    "        \n",
    "cf3P = np.zeros((1,7))\n",
    "for i in range (1):\n",
    "    for j in range (7):\n",
    "        cf_1 = y_pred3P.item((i,j))-label_cf3P.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf3P, [7*i+j], [cf_2]);\n",
    "        \n",
    "cf5N = np.zeros((1,7))\n",
    "for i in range (1):\n",
    "    for j in range (7):\n",
    "        cf_1 = y_pred5N.item((i,j))-label_cf5N.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf5N, [7*i+j], [cf_2]);\n",
    "        \n",
    "cf5P = np.zeros((1,7))\n",
    "for i in range (1):\n",
    "    for j in range (7):\n",
    "        cf_1 = y_pred5P.item((i,j))-label_cf5P.item((i,0));\n",
    "        cf_2 = 10*cf_1;\n",
    "        np.put(cf5P, [7*i+j], [cf_2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtest, y_pred, label_cf, cf\n",
    "y_pred_SA = np.hstack ((y_pred0, y_pred1N, y_pred1P,y_pred3N,y_pred3P,y_pred5N,y_pred5P)).reshape (7,7)\n",
    "label_SA = np.hstack ((label_cf0,label_cf1N,label_cf1P,label_cf3N,label_cf3P,label_cf5N,label_cf5P)).reshape (7,1)\n",
    "np.savetxt('SA_trainC_y_pred.csv', y_pred_SA, delimiter = ',')\n",
    "np.savetxt('SA_trainC_label.csv', label_SA , delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.037866]] [[-0.25337115]] [[ 0.17763914]] [[-0.68438145]] [[ 0.60864944]] [[-1.11539174]] [[ 1.03965973]]\n",
      "[[ 0.14826779  0.03344367 -0.02140237  0.04901839  0.02282612 -0.07494798\n",
      "   0.06013325]] [[ 0.89901654 -0.00708213 -0.33506348  0.20837421 -0.24941571 -0.45076948\n",
      "   0.14607549]] [[-0.71446683 -0.27576536  0.0263982  -0.28410631 -0.34489609  0.41007508\n",
      "  -0.4192666 ]] [[ 1.64885384 -1.51526968 -2.04829462 -0.31803829 -2.70395661 -0.8755814\n",
      "  -0.66689466]] [[-2.09868726 -1.262332    0.44139464 -1.09901402 -2.01740421  2.2359993\n",
      "  -1.44692378]] [[ 1.44104537 -4.91199343 -4.6057323  -2.06717101 -6.62341896 -0.53270987\n",
      "  -1.45365711]] [[-2.33254266 -1.92193007  2.71430254 -1.78144148 -3.36117565  5.93862669\n",
      "  -0.64968121]]\n"
     ]
    }
   ],
   "source": [
    "a = np.mean (x_test0).reshape (1,1)\n",
    "b = np.mean (x_test1N).reshape (1,1)\n",
    "c = np.mean (x_test1P).reshape (1,1)\n",
    "d = np.mean (x_test3N).reshape (1,1)\n",
    "e = np.mean (x_test3P).reshape (1,1)\n",
    "f = np.mean (x_test5N).reshape (1,1)\n",
    "g = np.mean (x_test5P).reshape (1,1)\n",
    "\n",
    "f0 = cf0*(-a)\n",
    "f1N = cf1N*(-b)\n",
    "f1P = cf1P*(-c)\n",
    "f3N = cf3N*(-d)\n",
    "f3P = cf3P*(-e)\n",
    "f5N = cf5N*(-f)\n",
    "f5P = cf5P*(-g)\n",
    "\n",
    "print (a,b,c,d,e,f,g)\n",
    "print (f0,f1N,f1P,f3N,f3P,f5N,f5P)\n",
    "f_SA = np.hstack ((f0, f1N, f1P,f3N,f3P,f5N,f5P)).reshape (7,7)\n",
    "np.savetxt('SA_trainC_f.csv', f_SA, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
